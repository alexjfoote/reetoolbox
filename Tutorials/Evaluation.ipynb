{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating a model's robustness\n",
        "\n",
        "This notebook will take you through the process of evaluating the robustness of a trained model to some of the available transforms.\n",
        "\n",
        "If you haven't already, make a copy of this Tutorials directory and put it in the directory you want to work in."
      ],
      "metadata": {
        "id": "wz7iDo-Lc88E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the toolbox"
      ],
      "metadata": {
        "id": "BL2kUSNs1By2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reetoolbox"
      ],
      "metadata": {
        "id": "I0ptbWox0-R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You must set the variable PATH to the directory containing this file."
      ],
      "metadata": {
        "id": "rPdr9VY2gOO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"\""
      ],
      "metadata": {
        "id": "mW1qJ662f7_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some useful functions"
      ],
      "metadata": {
        "id": "-9eS-aOUgzue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reetoolbox.utils import load_resnet, load_pannuke, get_dataloader"
      ],
      "metadata": {
        "id": "eZzLHgi6gyJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the device we're using and the class names"
      ],
      "metadata": {
        "id": "GCjXy6qtliub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "classes = [\"Negative\", \"Positive\"]"
      ],
      "metadata": {
        "id": "_Ge-m5a_lf46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load an existing model trained to classify Whole Slide Image patches as non-tumorous (negative) or tumorous (positive)."
      ],
      "metadata": {
        "id": "gD0k8lSRgM6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(PATH, \"Models/\" + model_names[0])\n",
        "model = load_resnet(model_path, device=device)"
      ],
      "metadata": {
        "id": "0Znhqb7idR38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the corresponding PanNuke dataset (see https://jgamper.github.io/PanNukeDataset/,  J. Gamper, N. A. Koohbanani, K. Benet, A. Khuram, and N. Rajpoot,\n",
        "“PanNuke: An Open Pan-Cancer Histology Dataset for Nuclei Instance\n",
        "Segmentation and Classification,” in Digital Pathology, pp. 11–19,\n",
        "Springer, Cham, Apr. 2019.)"
      ],
      "metadata": {
        "id": "mKUNP8gYhNi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = os.path.join(PATH, \"Data/breast_folds.npz\")\n",
        "Xtr, ytr, Xts, yts = load_pannuke(data_path)"
      ],
      "metadata": {
        "id": "PkYwv15Xgvkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a PyTorch dataset and dataloaders, which we give to the evaluator later. We can specify the number of examples to include in the dataloaders, to control how much of the dataset we use for evaluation."
      ],
      "metadata": {
        "id": "FulYIBk0jjI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torch.utils.data.TensorDataset(Xts, yts)\n",
        "\n",
        "batch_size = 4\n",
        "small_loader = get_dataloader(test_dataset, n=100, batch_size=batch_size)\n",
        "full_loader =  get_dataloader(test_dataset, n=None, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "qFbHbfosjg_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import transforms, optimisers, the evaluator, and some metrics from the toolbox, as well as some more handy functions"
      ],
      "metadata": {
        "id": "vcJRMvk7kpe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reetoolbox.utils import plot_change, display_results\n",
        "\n",
        "from reetoolbox.transforms import StainTransform, RotateTransform\n",
        "from reetoolbox.optimisers import PGD, StochasticSearch\n",
        "from reetoolbox.evaluator import Evaluator\n",
        "from reetoolbox.metrics import accuracy, adversarial_accuracy, fooling_rate, get_metrics"
      ],
      "metadata": {
        "id": "Lbz5QJFLjzlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set up an evaluator object that uses the stain transform. To do this, we need to give the evaluator our model, dataset, dataloader, optimiser, transform, optimiser parameters, transform parameters, and device.\n",
        "\n",
        "Of these, we still need to get the optimiser and transform parameters. The simplest way is to load the default parameters from `constants.py`. The naming convention is `eval_(transform name)_(transform or optimiser)_params`. For example, below we access the optimiser parameters for the stain transform using `eval_stain_optimiser_params`."
      ],
      "metadata": {
        "id": "VMB9KZkmlznZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reetoolbox.constants import eval_stain_transform_params, eval_stain_optimiser_params\n",
        "\n",
        "# Create the evaluator\n",
        "stain_evaluator = Evaluator(model, test_dataset, small_loader, PGD, \n",
        "                            StainTransform, eval_stain_optimiser_params, \n",
        "                            eval_stain_transform_params, device=device)"
      ],
      "metadata": {
        "id": "uz4XeoYIZBsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the evaluator to get the results of the model on the data. By passing `adversarial=True`, we get the results on both the normal and adversarially transformed data. We can then pass the results object to metric functions measure various aspects of performance."
      ],
      "metadata": {
        "id": "ueXXYm_Rn-Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = stain_evaluator.predict(adversarial=True)\n",
        "\n",
        "# Compute some specific metrics\n",
        "acc = accuracy(results)\n",
        "robust_acc = adversarial_accuracy(results)\n",
        "fool_rate = fooling_rate(results)\n",
        "print(f\"Accuracy: {acc:.3f}, robust accuracy: {robust_acc:.3f}, fooling rate: {fooling_rate:.3f}\")\n",
        "\n",
        "# Compute a standard set of metrics\n",
        "get_metrics(results)"
      ],
      "metadata": {
        "id": "EJJwZNemnfcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also define custom parameters for an evaluator, using the default as a template and changing the values as desired.\n",
        "\n",
        "The PGD optimiser requires epsilon, which is essentially the learning rate; steps, the number of steps of gradient descent; constraint, the name of an available constraint function (L0, L1, L2, L_inf, or in_range); C, the maximum magnitude of the perturbation as measured by the constraint function; and input_range, the minimum and maximum possible input values.\n",
        "\n",
        "This stain transform only requires the input range for the data."
      ],
      "metadata": {
        "id": "qYf_bdkUaAJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimiser parameters\n",
        "stain_optimiser_params = {\n",
        "    \"epsilon\": 0.01,\n",
        "    \"steps\": 20,\n",
        "    \"constraint\": \"l2\",\n",
        "    \"C\": 0.25,\n",
        "    \"input_range\": (0, 255)\n",
        "}\n",
        "# Define the transform parameters\n",
        "stain_transform_params = {\n",
        "    \"input_range\": (0, 255)\n",
        "}\n",
        "# Create the evaluator\n",
        "stain_evaluator = Evaluator(model, test_dataset, small_loader, PGD, \n",
        "                            StainTransform, stain_optimiser_params, \n",
        "                            stain_transform_params, device=device)\n",
        "\n",
        "results = stain_evaluator.predict(adversarial=True)\n",
        "\n",
        "# Compute a standard set of metrics\n",
        "get_metrics(results)"
      ],
      "metadata": {
        "id": "I60JrYOGlpDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also easily define a new metric if required. "
      ],
      "metadata": {
        "id": "vYsZNJntpPPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def adversarial_f1(results):\n",
        "    labels = results[\"labels\"]\n",
        "    outputs = results[\"adversarial_outputs\"]\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    return f1_score(labels, predictions)\n",
        "\n",
        "robust_f1 = adversarial_f1(results)\n",
        "print(f\"Robust F1 score: {robust_f1:.3f}\")"
      ],
      "metadata": {
        "id": "ftDDn62top_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the evaluator to measure how varying an optimiser parameter affects a metric."
      ],
      "metadata": {
        "id": "7UDIkyTVqK_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose an optimiser parameter\n",
        "param = \"C\"\n",
        "\n",
        "# Choose a range of values\n",
        "param_range = (0, 0.5)\n",
        "\n",
        "# Choose the step size - the metric will be computed at each value of the \n",
        "# parameter\n",
        "step_size = 0.02\n",
        "\n",
        "# Choose a metric\n",
        "metric = adversarial_accuracy\n",
        "\n",
        "# Use the evaluator to compute the metric over the range of parameter values\n",
        "# Set the kwargs to compute the correct set of results for the metric - in this\n",
        "# case we need to adversarially perturb the images, so we set adversarial to\n",
        "# True\n",
        "param_values, all_scores = stain_evaluator.metric_vs_strength(param, param_range, \n",
        "                                                              step_size, metric,\n",
        "                                                              adversarial=True)\n",
        "\n",
        "# Use the helper function to plot the scores against the parameter values\n",
        "fig = plot_change(param_values, all_scores, xlabel=param, \n",
        "                  ylabel=\"Adversarial Accuracy\", x_range=param_range, \n",
        "                  y_range=(0, 1.1))"
      ],
      "metadata": {
        "id": "0WYOpAM6po0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can transform specific inputs by passing a list of indices to the evaluator, and visualise the results"
      ],
      "metadata": {
        "id": "15WGhsk6qqUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, adv_inputs = stain_evaluator.attack_inputs([0])\n",
        "for i, input_ in enumerate(inputs):\n",
        "    display_results(input_, adv_inputs[i], classes)"
      ],
      "metadata": {
        "id": "VCcPuMDiqpEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have an example of using a transform with stochastic search. To demonstrate how this differs from using PGD we manually define the optimiser and transform parameters below, but you could also simply import them from `constants.py` as shown previously. \n",
        "\n",
        "Note that the optimiser parameters are different. We define: `samples`, the number of randomly sampled parameter sets we test; `weight_ranges`, a dictionary with the name of each parameter in `self.weights` as keys and tuples defining the range of values that each parameter can take as values; and `input_range`, the minimum and maximum values the input data could take.\n",
        "\n",
        "We define any necessary transform parameters - in this case we don't need any - and create an evaluator in the same way as before."
      ],
      "metadata": {
        "id": "ZfaOs5v8V2sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotate_optimiser_params = {\n",
        "    \"samples\": 20,\n",
        "    \"weight_ranges\": {\n",
        "        \"angle\": (0, 360)\n",
        "    },\n",
        "    \"input_range\": (0, 255)\n",
        "}\n",
        "\n",
        "rotate_transform_params = {\n",
        "}\n",
        "\n",
        "rotate_evaluator = Evaluator(model, test_dataset, small_loader, StochasticSearch, \n",
        "                             RotateTransform, rotate_optimiser_params, \n",
        "                             rotate_transform_params, device=device)"
      ],
      "metadata": {
        "id": "j68i2wliVPZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do all the same operations as before, like measuring robustness and visualising the effects of the transform."
      ],
      "metadata": {
        "id": "ldrP-reTYZbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = rotate_evaluator.predict(adversarial=True)\n",
        "\n",
        "# Compute a standard set of metrics\n",
        "get_metrics(results)\n",
        "\n",
        "inputs, adv_inputs = rotate_evaluator.attack_inputs([0])\n",
        "for i, input_ in enumerate(inputs):\n",
        "    display_results(input_, adv_inputs[i], classes)"
      ],
      "metadata": {
        "id": "dFOak3JpYSSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define new transforms to work with the existing optimisers. Below we show how to define a transform for use with the PGD optimiser."
      ],
      "metadata": {
        "id": "X3Rf2bukr1r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "from reetoolbox.transforms import Transform\n",
        "\n",
        "class MeanTransform(Transform):\n",
        "    # The class inherits from the abstract class Transform\n",
        "    def __init__(self, input_shape, device, input_range=(0, 255), noise_range=(-0.1, 0.1)):\n",
        "        # This method must take input_shape and device and input, and can \n",
        "        # optionally take any other desired arguments\n",
        "        super().__init__(input_shape, device)\n",
        "\n",
        "        self.input_range = input_range\n",
        "        batch_size = input_shape[0]\n",
        "        shape = (batch_size, 1)\n",
        "\n",
        "        # self.base_weights defines the base perturbation from which to measure\n",
        "        # the magnitude of the perturbation. Often it will be a tensor of zeros\n",
        "        self.base_weights = torch.zeros(shape).to(device)\n",
        "\n",
        "        # self.weights is a tensor with a grad function that will be optimised\n",
        "        # using the provided optimiser to cause misclassification\n",
        "        weights = torch.FloatTensor(*shape).uniform_(*noise_range).to(device)\n",
        "        self.weights = Variable(weights, requires_grad=True).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We want to use this transfrom with PGD, so this must perform a \n",
        "        # differentiable (with respect to self.weights) transform on the inputs \n",
        "        # x. The transform is parameterised by self.weights\n",
        "        for i in range(self.input_shape[0]):\n",
        "            x[i] = torch.clamp(x[i] + self.weights[i], *self.input_range)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OYeGN9AIrDpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an evaluator using our new transform\n",
        "mean_optimiser_params = {\n",
        "    \"epsilon\": 0.5,\n",
        "    \"steps\": 20,\n",
        "    \"constraint\": \"l2\",\n",
        "    \"C\": 30,\n",
        "    \"input_range\": (0, 255)\n",
        "}\n",
        "\n",
        "mean_transform_params = {\n",
        "    \"input_range\": (0, 255)\n",
        "}\n",
        "\n",
        "mean_evaluator = Evaluator(model, test_dataset, small_loader, PGD, \n",
        "                           MeanTransform, mean_optimiser_params, \n",
        "                           mean_transform_params, device=device)\n",
        "\n",
        "results = mean_evaluator.predict(adversarial=True)\n",
        "get_metrics(results)"
      ],
      "metadata": {
        "id": "Nk9pRUXrsE_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}